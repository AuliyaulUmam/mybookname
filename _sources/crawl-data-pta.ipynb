{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmHlJdfp9dqo"
   },
   "source": [
    "# Data Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BZ_3klr9ivE"
   },
   "source": [
    "Dara Crawling atau penyerapan data adalah proses pengambilan data yang tersedia secara online untuk umum. Proses ini kemudian mengimpor informasi atau data yang telah ditemukan ke dalam file lokal di komputer Anda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-Olq5A-9qjE"
   },
   "source": [
    "## Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvUDkUi7-J4Z"
   },
   "source": [
    "Kerangka kerja aplikasi untuk crawling web site dan mengekstraksi data terstruktur yang dapat digunakan untuk berbagai aplikasi yang bermanfaat, seperti data mining, pemrosesan informasi atau arsip sejarah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XaCa-2h-OJn"
   },
   "source": [
    "## Install Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qImjuzCj9TIn"
   },
   "outputs": [],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF4hMyxO-4YE"
   },
   "source": [
    "## Membuat file Project Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqxGixFc-xmt",
    "outputId": "e93a8d1f-876b-4f14-aa8e-c817bda38cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'scrapyPTA', using template directory '/usr/local/lib/python3.7/dist-packages/scrapy/templates/project', created in:\n",
      "    /content/drive/MyDrive/Tugas_PPW/scrapyPTA\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd scrapyPTA\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject scrapyPTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue3xhR2N_AN5"
   },
   "source": [
    "## Masuk ke Folder Project yang dibuat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2kYwchV_Afp",
    "outputId": "58ad00a9-07d9-4a9b-f2bd-62ab3972436b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Tugas_PPW/scrapyPTA\n"
     ]
    }
   ],
   "source": [
    "%cd scrapyPTA/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvonV9v__Ays"
   },
   "source": [
    "## Membuat File Spider\n",
    "Membuat File Spider dan memasukkan url yang akan diambil datanya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itbRbgok_A9R",
    "outputId": "30e9e17c-f154-474d-9b57-6a54022df75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spider 'webpta' using template 'basic' in module:\n",
      "  scrapyPTA.spiders.webpta\n"
     ]
    }
   ],
   "source": [
    "!scrapy genspider webpta pta.trunojoyo.ac.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeFZ-msmAo57"
   },
   "source": [
    "## Menuliskan Program Scapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFhaBNxxAxr7"
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class WebptaSpider(scrapy.Spider):\n",
    "    name = 'webpta'\n",
    "    allowed_domains = ['pta.trunojoyo.ac.id']\n",
    "    start_urls = ['https://pta.trunojoyo.ac.id/c_search/byprod/12/'+str(x)+\" \" for x in range(2,20)]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for detail in response.css('a.gray.button::attr(href)'): \n",
    "            yield response.follow(detail.get(), callback = self.parse_detail)\n",
    "\n",
    "    def parse_detail(self, response):\n",
    "        for data in response.css('#content_journal > ul > li'):\n",
    "            yield{\n",
    "                'Abstraksi': data.css('div:nth-child(2) > p::text').get().replace('\\n\\n|\\n','').replace('ABSTRAK', '')\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzL2dIsNBBL3"
   },
   "source": [
    "## Jalankan File Spider\n",
    "Untuk Menjalankan file spider anda harus masuk ke directory file tersebut terlebih dahulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99QSTPBTBBUz",
    "outputId": "660499fd-3ae5-454f-97aa-93f40539a3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Tugas_PPW/scrapyPTA/scrapyPTA/spiders\n"
     ]
    }
   ],
   "source": [
    "%cd scrapyPTA/spiders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQ8RzOMLBRtj",
    "outputId": "e6bba2a6-5420-4a89-e8c9-ebcc54eb8bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-16 18:20:05 [scrapy.utils.log] INFO: Scrapy 2.6.3 started (bot: scrapyPTA)\n",
      "2022-10-16 18:20:05 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.14 (default, Sep  8 2022, 00:06:44) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
      "2022-10-16 18:20:05 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'scrapyPTA',\n",
      " 'NEWSPIDER_MODULE': 'scrapyPTA.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_LOADER_WARN_ONLY': True,\n",
      " 'SPIDER_MODULES': ['scrapyPTA.spiders']}\n",
      "2022-10-16 18:20:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2022-10-16 18:20:05 [scrapy.extensions.telnet] INFO: Telnet Password: 11bfcb82ae709d4a\n",
      "2022-10-16 18:20:05 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2022-10-16 18:20:05 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2022-10-16 18:20:05 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2022-10-16 18:20:05 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2022-10-16 18:20:05 [scrapy.core.engine] INFO: Spider opened\n",
      "2022-10-16 18:20:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2022-10-16 18:20:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2022-10-16 18:20:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://pta.trunojoyo.ac.id/robots.txt> from <GET http://pta.trunojoyo.ac.id/robots.txt>\n",
      "/usr/local/lib/python3.7/dist-packages/scrapy/core/engine.py:279: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated\n",
      "  return self.download(result, spider) if isinstance(result, Request) else result\n",
      "2022-10-16 18:20:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pta.trunojoyo.ac.id/robots.txt> (referer: None)\n",
      "2022-10-16 18:20:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://pta.trunojoyo.ac.id/> from <GET http://pta.trunojoyo.ac.id/>\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Attempting to acquire lock 140305739420112 on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Lock 140305739420112 acquired on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Attempting to acquire lock 140305739421584 on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Lock 140305739421584 acquired on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443\n",
      "2022-10-16 18:20:07 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 \"GET /list/public_suffix_list.dat HTTP/1.1\" 200 None\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Attempting to release lock 140305739421584 on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Lock 140305739421584 released on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Attempting to release lock 140305739420112 on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [filelock] DEBUG: Lock 140305739420112 released on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pta.trunojoyo.ac.id/> (referer: None)\n",
      "2022-10-16 18:20:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2022-10-16 18:20:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 896,\n",
      " 'downloader/request_count': 4,\n",
      " 'downloader/request_method_count/GET': 4,\n",
      " 'downloader/response_bytes': 7306,\n",
      " 'downloader/response_count': 4,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/301': 2,\n",
      " 'elapsed_time_seconds': 2.001892,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2022, 10, 16, 18, 20, 7, 358303),\n",
      " 'httpcompression/response_bytes': 17488,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 15,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 141221888,\n",
      " 'memusage/startup': 141221888,\n",
      " 'response_received_count': 2,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2022, 10, 16, 18, 20, 5, 356411)}\n",
      "2022-10-16 18:20:07 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider webpta.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOWRDqwwBBdO"
   },
   "source": [
    "## Menyimpan data abstrak ke format CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBKty4lgBBl3",
    "outputId": "5384945d-44bc-4f42-d37f-ed89cfc880a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-16 18:20:47 [scrapy.utils.log] INFO: Scrapy 2.6.3 started (bot: scrapyPTA)\n",
      "2022-10-16 18:20:47 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.14 (default, Sep  8 2022, 00:06:44) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
      "2022-10-16 18:20:47 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'scrapyPTA',\n",
      " 'NEWSPIDER_MODULE': 'scrapyPTA.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['scrapyPTA.spiders']}\n",
      "2022-10-16 18:20:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2022-10-16 18:20:47 [scrapy.extensions.telnet] INFO: Telnet Password: 855e7607367753d2\n",
      "2022-10-16 18:20:47 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2022-10-16 18:20:47 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2022-10-16 18:20:47 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2022-10-16 18:20:47 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2022-10-16 18:20:47 [scrapy.core.engine] INFO: Spider opened\n",
      "2022-10-16 18:20:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2022-10-16 18:20:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2022-10-16 18:20:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://pta.trunojoyo.ac.id/robots.txt> from <GET http://pta.trunojoyo.ac.id/robots.txt>\n",
      "/usr/local/lib/python3.7/dist-packages/scrapy/core/engine.py:279: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated\n",
      "  return self.download(result, spider) if isinstance(result, Request) else result\n",
      "2022-10-16 18:20:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pta.trunojoyo.ac.id/robots.txt> (referer: None)\n",
      "2022-10-16 18:20:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://pta.trunojoyo.ac.id/> from <GET http://pta.trunojoyo.ac.id/>\n",
      "2022-10-16 18:20:49 [filelock] DEBUG: Attempting to acquire lock 140140614642448 on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:49 [filelock] DEBUG: Lock 140140614642448 acquired on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:49 [filelock] DEBUG: Attempting to release lock 140140614642448 on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:49 [filelock] DEBUG: Lock 140140614642448 released on /root/.cache/python-tldextract/3.7.14.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
      "2022-10-16 18:20:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://pta.trunojoyo.ac.id/> (referer: None)\n",
      "2022-10-16 18:20:49 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2022-10-16 18:20:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 896,\n",
      " 'downloader/request_count': 4,\n",
      " 'downloader/request_method_count/GET': 4,\n",
      " 'downloader/response_bytes': 7304,\n",
      " 'downloader/response_count': 4,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/301': 2,\n",
      " 'elapsed_time_seconds': 1.899857,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2022, 10, 16, 18, 20, 49, 736343),\n",
      " 'httpcompression/response_bytes': 17488,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 9,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 141402112,\n",
      " 'memusage/startup': 141402112,\n",
      " 'response_received_count': 2,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2022, 10, 16, 18, 20, 47, 836486)}\n",
      "2022-10-16 18:20:49 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl webpta -O crawlAbstrak.csv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
